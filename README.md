SOS 42 â€“ Multimodal Agentic RAG System

A production-grade agentic Retrieval-Augmented Generation (RAG) system that parses PDFs containing text, tables, and images, indexes them in a vector database, and enables grounded question answering through an explicit agentic reasoning layer.

Built as part of the SOS 42 AI Intern Assignment.

ğŸš€ Overview

This project implements an explicit agentic RAG architecture, where:

Documents are parsed into multimodal components (text, tables, images)

All components are embedded and stored in a vector database

Queries trigger deterministic retrieval

A dedicated Document Analysis Agent reasons over retrieved evidence

The agent generates a grounded answer with citations and visual references

The system is designed for accuracy, explainability, and extensibility, not just demo-level RAG.

ğŸ§  Why Agentic RAG?

Instead of a simple â€œretrieve â†’ generateâ€ pipeline, this system uses an explicit agent to:

Assess relevance of retrieved evidence

Decide how to use text vs tables vs images

Generate answers only from retrieved context

Return citations and visual references

This mirrors how modern production RAG systems are built in 2025+.

ğŸ—ï¸ Architecture
High-level flow
PDF Upload
   â†“
Multimodal Parsing (text / tables / images)
   â†“
Embeddings (OpenAI)
   â†“
Vector Store (Qdrant)
   â†“
Query
   â†“
Deterministic Retrieval
   â†“
Document Analysis Agent (LLM)
   â†“
Grounded Answer + Citations + Images

ğŸ“ Project Structure
sos42-rag-system/
â”œâ”€â”€ app/                        # Backend (FastAPI)
â”‚   â”œâ”€â”€ main.py                 # API entrypoint
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic schemas
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ document_parser.py  # PDF parsing (text, tables, images)
â”‚       â”œâ”€â”€ embeddings.py       # Embedding service (OpenAI)
â”‚       â”œâ”€â”€ vector_store.py     # Qdrant integration
â”‚       â””â”€â”€ rag_service.py      # Agentic RAG orchestration
â”‚
â”œâ”€â”€ frontend/                   # Frontend (Next.js)
â”‚   â””â”€â”€ src/app/
â”‚       â”œâ”€â”€ page.tsx            # Upload + Chat UI
â”‚       â”œâ”€â”€ layout.tsx
â”‚       â””â”€â”€ globals.css
â”‚
â”œâ”€â”€ outputs/images/             # Extracted images (served statically)
â”œâ”€â”€ docker-compose.yml          # Qdrant service
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ SETUP.md

ğŸ”‘ Key Features
âœ… Multimodal PDF Parsing

Extracts:

Text blocks

Tables

Images

Preserves metadata (page number, content type)

âœ… Vector Search with Qdrant

Document-scoped retrieval

Fast cosine similarity search

Production-ready storage layer

âœ… Explicit Agentic Reasoning

Dedicated Document Analysis Agent

Separates:

Retrieval (deterministic)

Reasoning (probabilistic)

Improves answer grounding and reliability

âœ… Grounded Answers

Responses are generated only from retrieved evidence

Citations included

Relevant images surfaced when applicable

âœ… Clean API Design

/upload â€“ upload and process PDFs

/query â€“ ask questions scoped to a document

/health â€“ system health check

ğŸ§ª Example Workflow

Upload a PDF

System parses and indexes all content

Ask:

â€œSummarize the key findings from section 3â€

System:

Retrieves relevant chunks

Agent analyzes evidence

Returns a concise answer with sources and images

ğŸ› ï¸ Tech Stack

Backend

FastAPI

OpenAI (embeddings + LLM)

Qdrant (vector database)

Unstructured (PDF parsing)

Frontend

Next.js (App Router)

Tailwind CSS

Framer Motion

Infrastructure

Docker (Qdrant)

Async Python (production-safe patterns)